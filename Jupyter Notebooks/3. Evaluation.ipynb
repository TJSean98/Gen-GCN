{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4384cdba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hausdorff\n",
      "  Downloading hausdorff-0.2.6.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: hausdorff\n",
      "  Building wheel for hausdorff (setup.py): started\n",
      "  Building wheel for hausdorff (setup.py): finished with status 'done'\n",
      "  Created wheel for hausdorff: filename=hausdorff-0.2.6-py3-none-any.whl size=15194 sha256=7206a7f5b556b562a53d3c41c0335eec94d8b68dc526c9321417b1dc1c3fd105\n",
      "  Stored in directory: c:\\users\\jsl3a\\appdata\\local\\pip\\cache\\wheels\\8d\\56\\ea\\fd4bbacf1217e197e63de821a74730e953b23fdf2030733061\n",
      "Successfully built hausdorff\n",
      "Installing collected packages: hausdorff\n",
      "Successfully installed hausdorff-0.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hausdorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c442128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/bc/43/a4a058fc1b58aa523b69141b98e51edf795fd0ff20e690dc8c1ed654c7fd/numba-0.57.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading numba-0.57.1-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba)\n",
      "  Obtaining dependency information for llvmlite<0.41,>=0.40.0dev0 from https://files.pythonhosted.org/packages/e7/fb/a7430788e80cff1ec512ba6ca6d2159c0ed6293530b0d502d171e299872f/llvmlite-0.40.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading llvmlite-0.40.1-cp39-cp39-win_amd64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<1.25,>=1.21 in c:\\users\\jsl3a\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages (from numba) (1.23.2)\n",
      "Downloading numba-0.57.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.5 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.3/2.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.40.1-cp39-cp39-win_amd64.whl (27.7 MB)\n",
      "   ---------------------------------------- 0.0/27.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/27.7 MB 16.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.1/27.7 MB 13.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.5/27.7 MB 12.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.0/27.7 MB 11.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.5/27.7 MB 11.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.1/27.7 MB 11.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.6/27.7 MB 11.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/27.7 MB 11.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.7/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.2/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.8/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.3/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.9/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.4/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 8.0/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.5/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 9.0/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 9.6/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 10.1/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.6/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.1/27.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.4/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.9/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 12.4/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.9/27.7 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.3/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.9/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.4/27.7 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 15.0/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 15.5/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.0/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.6/27.7 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 17.1/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.6/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 18.2/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 18.7/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.3/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 19.8/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.3/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.9/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.5/27.7 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 22.0/27.7 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.5/27.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.1/27.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.3/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.9/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.4/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.0/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.5/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.0/27.7 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.6/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.9/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.5/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.7/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.7/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.7/27.7 MB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.40.1 numba-0.57.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a21dff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import from_trimesh, to_trimesh#, to_edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca5b1b",
   "metadata": {},
   "source": [
    "# 1. Importing Mesh as Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0dee1",
   "metadata": {},
   "source": [
    "using the function from notebook: \"2.ASMG Framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247f460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimesh2datalist(input_path):\n",
    "    \"\"\"read all trimesh from input_path, append to a list and return the list\n",
    "\n",
    "    Args:\n",
    "        input_path: The path to the trimesh files.\n",
    "\n",
    "    Returns:\n",
    "        a list with all the trimesh object in the path\n",
    "    \"\"\"\n",
    "    #get item list to call functions on\n",
    "    item_list = os.listdir(input_path)\n",
    "    \n",
    "    list = []\n",
    "\n",
    "    #for all the item in input folder:\n",
    "    for i in range(len(item_list)):\n",
    "        in_path = input_path+\"\\\\\"+item_list[i]#set input path, start from folder\n",
    "        mesh = trimesh.load(in_path)\n",
    "        item = from_trimesh(mesh)\n",
    "        list.append(item)\n",
    "    \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7010345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.08 minutes\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:\\\\Users\\jsl3a\\Desktop\\MSc Project Dataset\\\\nnUNet_raw\\\\Dataset001_amosCT\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#load training and validation data into lists\n",
    "ori_data = trimesh2datalist(\"version1/gb_stl_tr\")\n",
    "vgae_data = trimesh2datalist(\"version1/vgae_mesh\")\n",
    "recon_data = trimesh2datalist(\"version1/test\")\n",
    "#will do more in the future when we can implement baseline model & refinement loss\n",
    "   \n",
    "elapsed_time_min = (time.time() - start_time)/60\n",
    "print(f\"Elapsed time: {elapsed_time_min:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0cace",
   "metadata": {},
   "source": [
    "remove the template mesh from original data, make both list comparable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fda105f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = ori_data[:17] + ori_data[18:]\n",
    "vgae_data = vgae_data[:17] + vgae_data[18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afb8e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "162\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "print(len(ori_data))\n",
    "print(len(vgae_data))\n",
    "print(len(recon_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e634f",
   "metadata": {},
   "source": [
    "We will randomly select 5 datapoints from the list for visualisation purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7692e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_list = []\n",
    "# recon_list = []\n",
    "\n",
    "# for i in range(5):\n",
    "#     r = np.random.randint(0, len(ori_data))\n",
    "#     ori_list.append(ori_data[r])\n",
    "#     recon_list.append(recon_data[r])\n",
    "#     print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15b885",
   "metadata": {},
   "source": [
    "# 2. Evaluation\n",
    "\n",
    "Although we were not able to recreate good synthetic shapes, we will still proceed to the evaluation stage, to complete this project.\n",
    "\n",
    "The evaluation will again refer to Soodeh's paper, but will less metrics and aspects. We will focus on the **Generation Quality** and use the **Hausdorff Distance (HD)** & the **average of minimum Euclidean distance (ED)** for the metrics.\n",
    "\n",
    "(p.s.) At the stage of writing we are not able to find code for the baseline model, the *rigid Registration-based Shape Matching (RSM)*, thus we don't have a base model yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef9471",
   "metadata": {},
   "source": [
    "## 2.1 Hausdorff Distance (HD)\n",
    "\n",
    "The HD metric will make use of the `hausdorff_distance` function from the library `hausdorff` installed above. ([github](https://github.com/mavillan/py-hausdorff/tree/master))\\\n",
    "The function only takes numpy array as input, so we will have to convert the data from tensor to array before called the function over our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "47059083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, stdev\n",
    "from hausdorff import hausdorff_distance\n",
    "\n",
    "#function to convert list of tensor to list of numpy\n",
    "def tensor2numpy(list):\n",
    "    length = len(list)\n",
    "    new_list = []\n",
    "    for i in range(length):\n",
    "        arr = list[i].pos.numpy()\n",
    "        new_list.append(arr)\n",
    "    return new_list\n",
    "\n",
    "#function to call hausdorff_distance over whole dataset and return average distance/data\n",
    "def hd_over_lists(list1, list2): #the list here is ndarray\n",
    "    len1 = len(list1)\n",
    "    len2 = len(list2)\n",
    "    total_hd = 0\n",
    "    \n",
    "    if (len1 != len2):\n",
    "        return None\n",
    "    for i in range(len1):\n",
    "        hd = hausdorff_distance(list1[i], list2[i])\n",
    "        total_hd += hd\n",
    "    return total_hd/len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c89a51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_datanp = tensor2numpy(ori_data)\n",
    "vgae_datanp = tensor2numpy(vgae_data)\n",
    "recon_datanp = tensor2numpy(recon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8880f8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausdorff distance between original data and vgae recon data: 82.0366\n",
      "Hausdorff distance between original data and ASMG recon data: 12890993379.5971\n"
     ]
    }
   ],
   "source": [
    "hd0 = hd_over_lists(ori_datanp, vgae_datanp)\n",
    "hd = hd_over_lists(ori_datanp, recon_datanp)\n",
    "print(f\"Hausdorff distance between original data and vgae recon data: {hd0:.4f}\")\n",
    "print(f\"Hausdorff distance between original data and ASMG recon data: {hd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0d480",
   "metadata": {},
   "source": [
    "Again, the reconstructed data as seen in the report or previous notebook is not ideal (looks nothing like the gallbladder mesh), which explains the ginormous average value here after looping through the datasets. \n",
    "\n",
    "I brought in the vgae reconstructed mesh just for reference.\n",
    "* it is not structurally normalised, just having the node features passed through the VGAE & recreated\n",
    "* the same data was used for training, so it will overfit and have very low HD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee39cb",
   "metadata": {},
   "source": [
    "## 2.2 Average Minimum Euclidean Distance (ED)\n",
    "\n",
    "This metric is calclulated using the pytorch function `PairwiseDistance` ([doc](https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance.html?highlight=distance)) where it defaults to computing the pairwise distance between input vectors, and the distance are computed using `p`-norm (defaulted to `p=2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ab5e4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to call ED calculation over whole dataset and return average distance/data\n",
    "def avg_min_ed_over_lists(list1, list2, dim): #the list here is tensor\n",
    "    len1 = len(list1)\n",
    "    len2 = len(list2)\n",
    "    total_ed = 0\n",
    "    \n",
    "    if (len1 != len2):\n",
    "        return None\n",
    "    for i in range(len1):\n",
    "        in1 = list1[i].pos\n",
    "        in2 = list2[i].pos\n",
    "        ed = torch.cdist(in1, in2)\n",
    "#         print(ed.shape)\n",
    "#         print(i, in1.shape, in2.shape, torch.min(ed))\n",
    "        min_by_0, _ = torch.min(ed, dim=dim)\n",
    "#         print(min_by_0.shape)\n",
    "        total_ed += torch.mean(min_by_0)\n",
    "    return total_ed/len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b15ad77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED between original data and vgae recon data: 57.6112\n",
      "ED between original data and ASMG recon data: 448079040.0000\n"
     ]
    }
   ],
   "source": [
    "#0 is the dimension of the 2nd tensor\n",
    "\n",
    "ed0 = avg_min_ed_over_lists(ori_data, vgae_data, 0)\n",
    "ed = avg_min_ed_over_lists(ori_data, recon_data, 0)\n",
    "print(f\"ED between original data and vgae recon data: {ed0:.4f}\")\n",
    "print(f\"ED between original data and ASMG recon data: {ed:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2d013bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1 is the dimension of the 1st tensor\n",
    "# ed0 = avg_min_ed_over_lists(ori_data, vgae_data, 1)\n",
    "# ed = avg_min_ed_over_lists(ori_data, recon_data, 1)\n",
    "# print(f\"ED between original data and vgae recon data: {ed0:.4f}\")\n",
    "# print(f\"ED between original data and ASMG recon data: {ed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd18ee",
   "metadata": {},
   "source": [
    "The results here are interesting.\n",
    "\n",
    "When we set the dimension in `torch.min` to `0`, which is the dimension ($|V_k^\\prime|$) of reconstructed data, we get a more reasonable result where the ED from the ASMG reconstruction is way bigger than the ED from the VGAE reconstruction.\n",
    "\n",
    "~~However, when we set the dimension to `1`, , which is the dimension ($|V_k|$) of original data,the ASMG reconstruction data actually have a lower ED than the VGAE reconstruction data.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2d5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
